---
title: "Main"
author: "Tan Hao Qin"
date: "2 August 2016"
output: pdf_document
---

```{r setup, include=FALSE, error=TRUE}
knitr::opts_chunk$set(echo = TRUE)
library('mlogit')
```

## Read data, always do this
```{r utility functions}
prediction_score <-function (actual, p){
  logloss <- 0
  N <- length(actual)
  for(i in 1:N){
    for(j in 1:4){
      y <- ifelse(as.integer(actual[i]) == j, 1, 0)
      p_score <- p[i,j]
      l <- log(as.numeric(p_score))
      logloss <- logloss + -1/N*y*l
    }
  }
  logloss
}

normalize_data <- function(D){
  D[,21:40] <- scale(D[,21:40])
  D[,5:7] <- scale(D[,5:7])
  D[,9:10] <- scale(D[,9:10])
  D
}
```

```{r read csv}
train <- read.csv('train.csv')
test <- read.csv('test.csv')
test2 <- read.csv('test.csv')
submission <- read.csv('samplesubmission.csv')
str(train)
str(test)
summary(train)
summary(test)
```


```{r format test data}
test$income <- lapply(test$income, as.character)
test$income <- factor(test$income,levels=levels(train$income))

Test <- mlogit.data(test, shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
Test$Ch1 = 0
Test$Ch2 = 0
Test$Ch3 = 0
Test$Ch4 = 0
Test$Choice = FALSE
```


```{r format train data with factors to numbers}
train2 <- read.csv('train.csv')
summary(train2)
str(train2)

#change gender, male = 1, female = 0
train2$gender <- ifelse(train2$gender == 'Male', 1, 0)


#change miles to avg of range, except over 400 which becomes 500
train2$miles <- factor(train2$miles, levels = c("Under 50 Miles","51 To 100 Miles","101 To 150 Miles","151 To 200 Miles","201 To 250 Miles","251 To 300 Miles","301 To 350 Miles","351 To 400 Miles","Over 400 Miles"))
table(train2$miles)
train2$miles <- (as.numeric(train2$miles)-1)*50 + 25
table(train2$miles)
train2$miles <- ifelse(train2$miles == 425, 500, train2$miles)
table(train2$miles)

#change night percentage to average of range
train2$night<- factor(train2$night, levels = c("Under 10%","10% To 20%","21% To 30%", "31% To 40%", "41% To 50%","51% To 60%","61% To 70%", "71% To 80%","81% To 90%","91% To 100%" ))
table(train2$night)
train2$night <- (as.numeric(train2$night)-1)*10+5
table(train2$night)

#change age to average of age, except over 60 changed to 70
train2$age <- factor(train2$age, levels = c("Under 30", "30 To 39", "40 To 49", "50 To 59", "60 & Over"))
table(train2$age)
train2$age <- (as.numeric(train2$age)-1)*10+25
train2$age <- ifelse(train2$age==65, 70, train2$age)

str(train2)


#change urbanisation, with Rural/Country = 0, Suburban = 1, Urban/City = 2
train2$Urb <- ifelse(train2$Urb=="Rural/Country", 0, ifelse(train2$Urb=="Suburban", 1, ifelse(train2$Urb=="Urban/City", 2, train2$Urb)))
str(train2$Urb)
str(train2)


#change education, Grade School = 0, High School = 1, Trade/Vocational School = 2, Some College (1-3 Years) = 3, College Graduate (4 Years) = 4, Postgraduate College = 5



train2$educ <- as.character(train2$educ)

train2$educ <- factor(train2$educ, levels = c("Grade School","High School","Trade/Vocational School","Some College (1-3 Years)","College Graduate (4 Years)","Postgraduate College"))
table(train2$educ)
train2$educ <- as.numeric(train2$educ)

str(train2$educ)

str(train2)

# change income to average of range
summary(train2$income)

train2$income <- factor(train2$income, levels = c("Under $29,999", "$30,000 to $39,999", "$40,000 to $49,999", "$50,000 to $59,999", "$60,000 to $69,999", "$70,000 to $79,999", "$80,000 to $89,999", "$90,000 to $99,999","$100,000 to $109,999", "$110,000 to $119,999", "$120,000 to $129,999", "$130,000 to $139,999", "$140,000 to $149,999", "$150,000 to $159,999", "$160,000 to $169,999", "$170,000 to $179,999", "$180,000 to $189,999", "$190,000 to $199,999", "$200,000 to $209,999", "$210,000 to $219,999", "$220,000 to $229,999","$230,000 to $239,999", "$240,000 to $249,999", "$250,000 to $259,999", "$260,000 to $269,999", "$270,000 to $279,999", "$280,000 to 2$89,999", "$290,000 to $299,999", "$300,000 & Over"))

table(train2$income)
train2$income <- (as.numeric(train$income)-1)*10000+25000
train2$income <- ifelse(train2$income==25000, 20000, ifelse(train2$income==245000, 250000, train2$income))

str(train2)

#change parking frequency to number of times per year
summary(train2$ppark)
head(train2$ppark)

train2$ppark <- as.character(train2$ppark)
train2$ppark <- factor(train2$ppark, levels = c("Never", "Yearly", "Monthly", "Weekly",  "Daily"))
train2$ppark <- ifelse(train2$ppark == "Never", 0, ifelse(train2$ppark =="Yearly", 1, ifelse(train2$ppark == "Monthly", 12,ifelse(train2$ppark == "Weekly", 52, ifelse(train2$ppark == "Daily", 365, train2$ppark)))))

summary(train2$ppark)

#ignore region, segment of car

```

```{r format test with numbers for factors}
test2$income <- lapply(test2$income, as.character)
test2$income <- factor(test2$income, levels=levels(train$income))

#change gender, male = 1, female = 0
test2$gender <- ifelse(test2$gender == 'Male', 1, 0)


#change miles to avg of range, except over 400 which becomes 500
test2$miles <- factor(test2$miles, levels = c("Under 50 Miles","51 To 100 Miles","101 To 150 Miles","151 To 200 Miles","201 To 250 Miles","251 To 300 Miles","301 To 350 Miles","351 To 400 Miles","Over 400 Miles"))
table(test2$miles)
test2$miles <- (as.numeric(test2$miles)-1)*50 + 25
table(test2$miles)
test2$miles <- ifelse(test2$miles == 425, 500, test2$miles)
table(test2$miles)

#change night percentage to average of range
test2$night<- factor(test2$night, levels = c("Under 10%","10% To 20%","21% To 30%", "31% To 40%", "41% To 50%","51% To 60%","61% To 70%", "71% To 80%","81% To 90%","91% To 100%" ))
table(test2$night)
test2$night <- (as.numeric(test2$night)-1)*10+5
table(test2$night)

#change age to average of age, except over 60 changed to 70
test2$age <- factor(test2$age, levels = c("Under 30", "30 To 39", "40 To 49", "50 To 59", "60 & Over"))
table(test2$age)
test2$age <- (as.numeric(test2$age)-1)*10+25
test2$age <- ifelse(test2$age==65, 70, test2$age)

str(test2)

#change urbanisation, with Rural/Country = 0, Suburban = 1, Urban/City = 2
test2$Urb <- ifelse(test2$Urb=="Rural/Country", 0, ifelse(test2$Urb=="Suburban", 1, ifelse(test2$Urb=="Urban/City", 2, test2$Urb)))
str(test2$Urb)
str(test2)


#change education, Grade School = 0, High School = 1, Trade/Vocational School = 2, Some College (1-3 Years) = 3, College Graduate (4 Years) = 4, Postgraduate College = 5

test2$educ <- as.character(test2$educ)

test2$educ <- factor(test2$educ, levels = c("Grade School","High School","Trade/Vocational School","Some College (1-3 Years)","College Graduate (4 Years)","Postgraduate College"))
table(test2$educ)
test2$educ <- as.numeric(test2$educ)

str(test2)

# change income to average of range
summary(test2$income)


test2$income <- factor(test2$income, levels = c("Under $29,999", "$30,000 to $39,999", "$40,000 to $49,999", "$50,000 to $59,999", "$60,000 to $69,999", "$70,000 to $79,999", "$80,000 to $89,999", "$90,000 to $99,999","$100,000 to $109,999", "$110,000 to $119,999", "$120,000 to $129,999", "$130,000 to $139,999", "$140,000 to $149,999", "$150,000 to $159,999", "$160,000 to $169,999", "$170,000 to $179,999", "$180,000 to $189,999", "$190,000 to $199,999", "$200,000 to $209,999", "$210,000 to $219,999", "$220,000 to $229,999","$230,000 to $239,999", "$240,000 to $249,999", "$250,000 to $259,999", "$260,000 to $269,999", "$270,000 to $279,999", "$280,000 to 2$89,999", "$290,000 to $299,999", "$300,000 & Over"))

table(test2$income)
test2$income <- (as.numeric(test$income)-1)*10000+25000
test2$income <- ifelse(test2$income==25000, 20000, ifelse(test2$income==245000, 250000, test2$income))
test2$income[is.na(test2$income)] <- mean(test2$income,na.rm=T)

str(test2)

#change parking frequency to number of times per year
summary(test2$ppark)
head(test2$ppark)

test2$ppark <- as.character(test2$ppark)
test2$ppark <- factor(test2$ppark, levels = c("Never", "Yearly", "Monthly", "Weekly",  "Daily"))
test2$ppark <- ifelse(test2$ppark == "Never", 0, ifelse(test2$ppark =="Yearly", 1, ifelse(test2$ppark == "Monthly", 12,ifelse(test2$ppark == "Weekly", 52, ifelse(test2$ppark == "Daily", 365, test2$ppark)))))

summary(test2$ppark)

#ignore region, segment of car


test2 <- mlogit.data(test2, shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
test2$Ch1 = 0
test2$Ch2 = 0
test2$Ch3 = 0
test2$Ch4 = 0
test2$Choice = FALSE

#install.packages("Amelia")
library(Amelia)
missmap(test2, main = "Missing values vs observed")

# all values are here
```

Tasks <= 12 are in D and tasks > 12 are in V
shape is wide because 4 choices are in the same row
```{r seperate train data for testing}
A <- mlogit.data(train, shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

D <- mlogit.data(subset(train, Task <= 12), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

V <- mlogit.data(subset(train, Task > 12), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
ActualChoice <- subset(train, Task > 12)[,"Choice"]
```

```{r seperate train2 data for testing with converted factors}
A2 <- mlogit.data(train2, shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

D2 <- mlogit.data(subset(train2, Task <= 12), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

V2 <- mlogit.data(subset(train2, Task > 12), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
ActualChoice2 <- subset(train2, Task > 12)[,"Choice"]

```


```{r seperating by gender}
A2male <- mlogit.data(subset(train2, train2$gender==1), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

A2female <- mlogit.data(subset(train2, train2$gender==0), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

D2male <- mlogit.data(subset(train2, Task <= 12 & gender==1), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

D2female <- mlogit.data(subset(train2, Task <= 12 & gender==0), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

V2male <- mlogit.data(subset(train2, Task > 12 & gender==1), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
ActualChoice2 <- subset(train2, Task > 12)[,"Choice"]

V2female <- mlogit.data(subset(train2, Task > 12 & gender==0), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
ActualChoice2 <- subset(train2, Task > 12)[,"Choice"]
ActualChoice2male <- subset(train2, Task > 12 & gender ==1)[,"Choice"]
ActualChoice2female <- subset(train2, Task > 12 & gender ==0)[,"Choice"]
```

```{r seperating by age}

A2old <- mlogit.data(subset(train2, train2$age>35), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

A2young <- mlogit.data(subset(train2, train2$age<36), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

D2old <- mlogit.data(subset(train2, Task <= 12 & age>35), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

D2young <- mlogit.data(subset(train2, Task <= 12 & age<36), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

V2old <- mlogit.data(subset(train2, Task > 12 & age>35), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
ActualChoice2 <- subset(train2, Task > 12)[,"Choice"]

V2young <- mlogit.data(subset(train2, Task > 12 & age<36), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

ActualChoice2 <- subset(train2, Task > 12)[,"Choice"]
ActualChoice2old <- subset(train2, Task > 12 & age>35)[,"Choice"]
ActualChoice2young <- subset(train2, Task > 12 & age<36)[,"Choice"]


```

```{r separating by night}
A2morenight <- mlogit.data(subset(train2, train2$night>26), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

A2lessnight <- mlogit.data(subset(train2, train2$night<27), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

D2morenight <- mlogit.data(subset(train2, Task <= 12 & night>26), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

D2lessnight <- mlogit.data(subset(train2, Task <= 12 & night<27), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

V2morenight <- mlogit.data(subset(train2, Task > 12 & night>26), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
ActualChoice2 <- subset(train2, Task > 12)[,"Choice"]

V2lessnight <- mlogit.data(subset(train2, Task > 12 & night<27), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

ActualChoice2 <- subset(train2, Task > 12)[,"Choice"]
ActualChoice2morenight <- subset(train2, Task > 12 & night>26)[,"Choice"]
ActualChoice2lessnight <- subset(train2, Task > 12 & night<27)[,"Choice"]

```


```{r seperating by income}
A2highincome <- mlogit.data(subset(train2, train2$income>200000), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

A2lowincome <- mlogit.data(subset(train2, train2$income<200001), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

D2highincome <- mlogit.data(subset(train2, Task <= 12 & income>200000), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

D2lowincome <- mlogit.data(subset(train2, Task <= 12 & income<200001), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

V2highincome <- mlogit.data(subset(train2, Task > 12 & income>200000), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
ActualChoice2 <- subset(train2, Task > 12)[,"Choice"]

V2lowincome <- mlogit.data(subset(train2, Task > 12 & income<200001), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

ActualChoice2 <- subset(train2, Task > 12)[,"Choice"]
ActualChoice2highincome <- subset(train2, Task > 12 & income>200000)[,"Choice"]
ActualChoice2lowincome <- subset(train2, Task > 12 & income<200001)[,"Choice"]
```


names(A2)

```{r seperating by segment}
summary(A2$segment)
A2fullsize_pickup <- mlogit.data(subset(train2, train2$segment=="Full-size Pickup"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
A2midsize_car <- mlogit.data(subset(train2, train2$segment=="Midsize Car"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
A2luxury_utility <- mlogit.data(subset(train2, train2$segment=="Midsize Luxury Utility segements"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
A2midsize_utility <- mlogit.data(subset(train2, train2$segment=="Midsize Utility"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
A2luxury_sedan <- mlogit.data(subset(train2, train2$segment=="Prestige Luxury Sedan"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
A2small_car <- mlogit.data(subset(train2, train2$segment=="Small Car"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
summary(A2$segment)

D2fullsize_pickup <- mlogit.data(subset(train2, Task <= 12 & train2$segment=="Full-size Pickup"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
D2midsize_car <- mlogit.data(subset(train2, Task <= 12 & train2$segment=="Midsize Car"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
D2luxury_utility <- mlogit.data(subset(train2, Task <= 12 & train2$segment=="Midsize Luxury Utility segements"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
D2midsize_utility <- mlogit.data(subset(train2, Task <= 12 & train2$segment=="Midsize Utility"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
D2luxury_sedan <- mlogit.data(subset(train2, Task <= 12 & train2$segment=="Prestige Luxury Sedan"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
D2small_car <- mlogit.data(subset(train2, Task <= 12 & train2$segment=="Small Car"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
summary(D2$segment)

ActualChoice2 <- subset(train2, Task > 12)[,"Choice"]

V2fullsize_pickup <- mlogit.data(subset(train2, Task > 12 & train2$segment=="Full-size Pickup"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
V2midsize_car <- mlogit.data(subset(train2, Task > 12 & train2$segment=="Midsize Car"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
V2luxury_utility <- mlogit.data(subset(train2, Task > 12 & train2$segment=="Midsize Luxury Utility segements"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
V2midsize_utility <- mlogit.data(subset(train2, Task > 12 & train2$segment=="Midsize Utility"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
V2luxury_sedan <- mlogit.data(subset(train2, Task > 12 & train2$segment=="Prestige Luxury Sedan"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
V2small_car <- mlogit.data(subset(train2, Task > 12 & train2$segment=="Small Car"), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
summary(V2$segment)

```


```{r generating data for proper cross validation}

start <- c(1, 4, 7, 10, 13, 16)
stop <- c(4, 7, 10, 13, 16, 19)

actualVector <- vector(mode = "list", length = 6)
trainVector <- vector(mode = "list", length = 6)
validateVector <- vector(mode = "list", length = 6)

for (i in 1:6){
  trainVector[[i]] <-mlogit.data(subset(train2, Task >= start[i]&Task < stop[i]), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")   
  validateVector[[i]] <-mlogit.data(subset(train2, !(Task >= start[i]&Task < stop[i])), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
    actualVector[[i]] <-subset(train2, !(Task >= start[i]&Task < stop[i]))[,'Choice']
  #normalize_data(trainVector[[i]])
  #normalize_data(validateVector[[i]])
}

```


```{r cv}

coef1 <- NA
coef2 <- NA
coef3 <- NA
coef4 <- NA

cvmodel1Vector <- vector(mode = "list", length = 6)
cvmodel2Vector <- vector(mode = "list", length = 6)
cvmodel3Vector <- vector(mode = "list", length = 6)
cvmodel4Vector <- vector(mode = "list", length = 6)
score1 <- c()
score2 <- c()
score3 <- c()
score4 <- c()

for (i in 1:6){
  cvmodel1Vector[[i]] <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb, data = trainVector[[i]])

  cvmodel2Vector[[i]] <- mlogit(Choice~GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+age+Urb, data = trainVector[[i]], reflevel = "Ch4")
  
  cvmodel3Vector[[i]] <- mlogit(Choice~GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+age+Urb, data = trainVector[[i]])
  
  cvmodel4Vector[[i]] <- mlogit(Choice~GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+age+Urb, data = trainVector[[i]])
  
  predictmodel1 <- predict(cvmodel1Vector[[i]], newdata = validateVector[[i]])
  predictmodel2 <- predict(cvmodel2Vector[[i]], newdata = validateVector[[i]])
  predictmodel3 <- predict(cvmodel3Vector[[i]], newdata = validateVector[[i]])
  predictmodel4 <- predict(cvmodel4Vector[[i]], newdata = validateVector[[i]])
  
  score1 <- c(score1, prediction_score(actualVector[[i]], predictmodel1))
  score2 <- c(score2, prediction_score(actualVector[[i]], predictmodel2))
  score3 <- c(score3, prediction_score(actualVector[[i]], predictmodel3))
  score4 <- c(score4, prediction_score(actualVector[[i]], predictmodel4))
  
  if(is.na(coef1)){
    coef1 <- summary(cvmodel1Vector[[i]])$CoefTable[,4]
    coef2 <- summary(cvmodel2Vector[[i]])$CoefTable[,4]
    coef3 <- summary(cvmodel3Vector[[i]])$CoefTable[,4]
    coef4 <- summary(cvmodel4Vector[[i]])$CoefTable[,4]
  } else {
    coef1 <- pmin(summary(cvmodel1Vector[[i]])$CoefTable[,4],coef1)
    coef2 <- pmin(summary(cvmodel2Vector[[i]])$CoefTable[,4],coef2)
    coef3 <- pmin(summary(cvmodel3Vector[[i]])$CoefTable[,4],coef3)
    coef4 <- pmin(summary(cvmodel4Vector[[i]])$CoefTable[,4],coef4)
  }
}

#model1
mean(score1)
#model2
mean(score2)
#model3
mean(score3)
mean(score4)
```

##Simple models
```{r model1 mlogit}
model1 <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = D)
summary(model1)

model3star <- mlogit(Choice~CC+BU+KA+SC+TS+MA+Price-1, data = D)
summary(model3star)

model2star <- mlogit(Choice~CC+BU+KA+SC+TS+MA+GN+LD+Price-1, data = D)
summary(model2star)

model1star <- mlogit(Choice~CC+BU+KA+SC+TS+MA+GN+LD+NS+BZ+RP+LB+HU+Price-1, data = D)
summary(model1star)
```

```{r validate}
predict1 <- predict(model1, newdata = V)
predict3star <- predict(model3star, newdata = V)
predict2star <- predict(model2star, newdata = V)
predict1star <- predict(model1star, newdata = V)

PredictChoice1 <- apply(predict1, 1, which.max)
PredictChoice3star <- apply(predict3star, 1, which.max)
PredictChoice2star <- apply(predict2star, 1, which.max)
PredictChoice1star <- apply(predict1star, 1, which.max)

t1 <- table(ActualChoice, PredictChoice1)
t3s <- table(ActualChoice, PredictChoice3star)
t2s <- table(ActualChoice, PredictChoice2star)
t1s <- table(ActualChoice, PredictChoice1star)

choiceVector <- vector(mode = "list", length = 4)
choiceVector[[1]] <- t1
choiceVector[[2]] <- t3s
choiceVector[[3]] <- t2s
choiceVector[[4]] <- t1s
```

model 1 with all variables is best
```{r compare accuracy}
accurate_cnt <- c()
for(i in 1:4){
  accurate_cnt <- c(accurate_cnt, 0)
  for(j in 1:4){
    accurate_cnt[i] <- accurate_cnt[i] + choiceVector[[i]][j,j]
  }
}
accurate_cnt
```



```{r pred1 mlogit all variables D data}
TestPredict <- predict(model1, newdata = Test)
Submission1 <- submission
for (i in 1:length(TestPredict)){
  for (j in colnames(TestPredict)){
    Submission1[i,j] = TestPredict[i,j]
  }
}
write.csv(Submission1, file = 'Submission1.csv')
```

```{r pred3 2nd best mlogit with 1star variables}
TestPredict <- predict(model1star, newdata = Test)
Submission3 <- submission
for (i in 1:length(TestPredict)){
  for (j in colnames(TestPredict)){
    Submission3[i,j] = TestPredict[i,j]
  }
}
write.csv(Submission3, file = 'Submission3.csv')
```

```{r model2 random parameters}
model2 <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = D, rpar = c(CC = 'n',  GN = 'n',  NS = 'n',  BU = 'n',  FA = 'n',  LD = 'n',  BZ = 'n',  FC = 'n',  FP = 'n',  RP = 'n',  PP = 'n',  KA = 'n',  SC = 'n',  TS = 'n',  NV = 'n',  MA = 'n',  LB = 'n',  AF = 'n',  HU = 'n', Price = 'n'), panel = TRUE, print.level = TRUE)
summary(model2)
```

```{r pred2 random parameter}
Pred2 <- predict(model2, newdata = Test)
Submission2 <- submission
for (i in 1:length(Pred2)){
  for (j in colnames(Pred2)){
    Submission2[i,j] = Pred2[i,j]
  }
}
write.csv(Submission2, file = 'Submission2.csv')
```



```{r pred4 mlogit with A data}
A <- mlogit.data(train, shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

model1A <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = A)
summary(model1A)

Pred1A <- predict(model1A, newdata = Test)
Submission4 <- submission
for (i in 1:nrow(Pred1A)){
  for (j in colnames(Pred1A)){
    Submission4[i,j] = Pred1A[i,j]
  }
}
write.csv(Submission4, file = 'Submission4.csv')
```

```{r pred5&6 mlogit with numerical factor data}

A <- mlogit.data(train, shape = 'wide', choice = "Choice", varying = c(c(4:83)), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")

model1A <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1 | gender+miles+night+age+Urb, data = A)
summary(model1A)

Pred1A <- predict(model1A, newdata = Test)
Submission6 <- submission
for (i in 1:nrow(Pred1A)){
  for (j in colnames(Pred1A)){
    Submission6[i,j] = Pred1A[i,j]
  }
}
write.csv(Submission6, file = 'Submission6.csv')

```

```{r model 7 with all factors}
model7_pre <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb, data = D2)
summary(model7_pre)


model7 <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb+educ+income+ppark, data = D2)
summary(model7)

model7_3star <- mlogit(Choice~GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1 | age+Urb, data = D2)
summary(model7_3star)

model7_2star <- mlogit(Choice~GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1 | age+Urb+ppark, data = D2)
summary(model7_2star)

model7_1star <- mlogit(Choice~GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1 | miles+age+Urb+educ+ppark, data = D2)
summary(model7_1star)

Pred7_pre <- predict(model7_pre, newdata = V2)
Pred7 <- predict(model7, newdata = V2)
Pred7_3star <- predict(model7_3star, newdata = V2)
Pred7_2star <- predict(model7_2star, newdata = V2)
Pred7_1star <- predict(model7_1star, newdata = V2)
```

```{r model 8 using glmnet}

library(glmnet)
newA2 <- A2[,4:41]
colnames(newA2)
x <- model.matrix(Choice~., newA2)
y <- newA2$Choice

grid <- 10^seq(10,-6,length=100)

set.seed(1)
glmnet_train<- sample(1:nrow(x), nrow(x)/2)
glmnet_test<- -glmnet_train

glm_model8<- glmnet(x[glmnet_train,], y[glmnet_train], family = 'multinomial', alpha=1, lambda = grid)
plot(glm_model8, xvar="lambda")

##BEST LAMBDA IS $lambda.min
set.seed(2)
cvlasso<- cv.glmnet(x[glmnet_train,], y[glmnet_train], alpha=1, family = 'multinomial')
cvlasso
#using D2 data, best lambda is 0.001681765
#gender+miles+night+age+Urb
#repeat above using D Data instead
#using D data, best lambda is 0.003885096
#using A data, best lambda is 0.002757943
#using A2 data, 0.001732069
#using newA2 data, 0.001732069
#using 2/3 of data for training

predictlasso<- predict(glm_model8, newx = x[glmnet_test,], s=cvlasso$lambda.min) #lambdaD2=0.001681765, lambdaD=0.003885096 lambdaA = 0.002757943 #lambdaA2 = 0.001732069 #lamdawith2/3 training set = 0.00131865
mean((predictlasso-y[glmnet_test])^2)
#mean squared error D2 is 0.1769509
#mean squared error D is 0.1770686
#mean squared error A is 0.1737358
#mean squared error A2 is 0.1736695
#mse 2/3 training set is 0.1720781


lassocoef <- predict(glm_model8, s = cvlasso$lambda.min, type ="coefficients")
?predict.glm
lassocoef
```
setwd("C:/Users/Susiwati/Dropbox/Susi/SUTD/40.220 The Analytics Edge/R/Susi/sutd-kaggle")


```{r validate model7}
PredictChoice7_pre <- apply(Pred7_pre, 1, which.max)
PredictChoice7 <- apply(Pred7, 1, which.max)
PredictChoice7_3star <- apply(Pred7_3star, 1, which.max)
PredictChoice7_2star <- apply(Pred7_2star, 1, which.max)
PredictChoice7_1star <- apply(Pred7_1star, 1, which.max)


t1_pre <- table(ActualChoice2, PredictChoice7_pre)
t1 <- table(ActualChoice2, PredictChoice7)
t3s <- table(ActualChoice2, PredictChoice7_3star)
t2s <- table(ActualChoice2, PredictChoice7_2star)
t1s <- table(ActualChoice2, PredictChoice7_1star)


choiceVector <- vector(mode = "list", length = 5)
choiceVector[[1]] <- t1_pre
choiceVector[[2]] <- t1
choiceVector[[3]] <- t3s
choiceVector[[4]] <- t2s
choiceVector[[5]] <- t1s

prediction_score(ActualChoice2,Pred7_pre)
prediction_score(ActualChoice2,Pred7)
prediction_score(ActualChoice2,Pred7_3star)
prediction_score(ActualChoice2,Pred7_2star)
prediction_score(ActualChoice2,Pred7_1star)

```

```{r model11 with gender split}
model7_pre_male <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| miles+night+age+Urb, data = D2male)

model7_pre_female <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| miles+night+age+Urb, data = D2female)

summary(model7_pre_male)
model7_pre_male$coefficients
summary(model7_pre_female)
model7_pre_female$coefficients

Pred11_maleV2 <- predict(model7_pre_male, newdata = V2)
Pred11_femaleV2 <- predict(model7_pre_female, newdata = V2)

# Orginal 
Pred11_tgt <- Pred11_maleV2

for(i in 1:nrow(Pred11_maleV2)){
  for (j in 1:4){
    Pred11_tgt[i,j] <- (Pred11_maleV2[i,j]+Pred11_femaleV2[i,j])/2
  }
}

# Split data set while keeping id (Number)
v2male_raw = subset(train2,Task > 12 & gender==1)
v2female_raw = subset(train2,Task > 12 & gender==0)
Pred11_male <- data.frame(predict(model7_pre_male, newdata = V2male))
Pred11_female <- data.frame(predict(model7_pre, newdata = V2female))
Pred11_gender_split <- data.frame(No = subset(train2,Task>12)[,"No"])
for(i in 1:nrow(v2male_raw)){
  Pred11_male$No[i] <- v2male_raw[i,"No"]
}
for(i in 1:nrow(v2female_raw)){
  Pred11_female$No[i] <- v2female_raw[i,"No"]
}
s <- rbind(Pred11_male,Pred11_female)
Pred11_gender_split = merge(x = Pred11_gender_split, y = s, by = "No")
Pred11_gender_split <- Pred11_gender_split[,-(1)]


PredictChoice11avg <- apply(Pred11_tgt, 1, which.max)

PredictChoice11male <- apply(Pred11_male, 1, which.max)
PredictChoice11female <- apply(Pred11_female, 1, which.max)

prediction_score(ActualChoice2, Pred7_pre)
prediction_score(ActualChoice2, Pred11_maleV2)
prediction_score(ActualChoice2female, Pred11_femaleV2)
prediction_score(ActualChoice2, Pred11_tgt)
prediction_score(ActualChoice2, Pred11_gender_split)
```


```{r model12 with age split}
model7_pre_old <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb, data = D2old)

model7_pre_young <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb, data = D2young)

summary(model7_pre_old)
model7_pre_old$coefficients
summary(model7_pre_young)
model7_pre_young$coefficients

Pred11_oldV2 <- predict(model7_pre_old, newdata = V2)
Pred11_youngV2 <- predict(model7_pre_young, newdata = V2)

Pred11_allages <- Pred11_oldV2

for(i in 1:nrow(Pred11_oldV2)){
  for (j in 1:4){
    Pred11_allages[i,j] <- (Pred11_oldV2[i,j]+Pred11_youngV2[i,j])/2
  }
}

# Split data set while keeping id (Number)
v2young_raw = subset(train2,Task > 12 & age<36)
v2old_raw = subset(train2,Task > 12 & age>35)
Pred11_old <- data.frame(predict(model7_pre_old, newdata = V2old))
Pred11_young <- data.frame(predict(model7_pre_young, newdata = V2young))
Pred11_age_split <- data.frame(No = subset(train2,Task>12)[,"No"])

for(i in 1:nrow(v2young_raw)){
  Pred11_young$No[i] <- v2young_raw[i,"No"]
}
for(i in 1:nrow(v2old_raw)){
  Pred11_old$No[i] <- v2old_raw[i,"No"]
}
s <- rbind(Pred11_old,Pred11_young)
Pred11_age_split = merge(x = Pred11_age_split, y = s, by = "No")
Pred11_age_split <- Pred11_age_split[,-(1)]

PredictChoice11avg <- apply(Pred11_allages, 1, which.max)

PredictChoice11old <- apply(Pred11_old, 1, which.max)
PredictChoice11young <- apply(Pred11_young, 1, which.max)

#prediction_score(ActualChoice, Pred7_pre)
#prediction_score(ActualChoice, Pred11_allages)
prediction_score(ActualChoice, Pred11_oldV2)
prediction_score(ActualChoice, Pred11_youngV2)
prediction_score(ActualChoice,Pred7_pre)
prediction_score(ActualChoice, Pred11_allages)
prediction_score(ActualChoice, Pred11_age_split)
```


```{r model13 with night split}
model7_pre_morenight <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb, data = D2morenight)


model7_pre_lessnight <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+age+Urb, data = D2lessnight)

summary(model7_pre_morenight)
model7_pre_morenight$coefficients
summary(model7_pre_lessnight)
model7_pre_lessnight$coefficients

Pred11_morenight <- predict(model7_pre_morenight, newdata = V2)
Pred11_lessnight <- predict(model7_pre, newdata = V2)

length(Pred11_lessnight)
Pred11_morenight[1,2]

Pred11_allnight <- Pred11_morenight

for(i in 1:nrow(Pred11_morenight)){
  for (j in 1:4){
    Pred11_allages[i,j] <- (Pred11_morenight[i,j]+Pred11_lessnight[i,j])/2
  }
}

PredictChoice11avg <- apply(Pred11_allages, 1, which.max)

PredictChoice11morenight <- apply(Pred11_morenight, 1, which.max)
PredictChoice11lessnight <- apply(Pred11_lessnight, 1, which.max)

prediction_score(ActualChoice, Pred7_pre)
prediction_score(ActualChoice, Pred11_allnight)
prediction_score(ActualChoice, Pred11_morenight)
prediction_score(ActualChoice, Pred11_lessnight)
```


```{r model14 with income split}
model7_pre_highincome <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb, data = D2highincome)


model7_pre_lowincome <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb, data = D2lowincome)

summary(model7_pre_highincome)
model7_pre_highincome$coefficients
summary(model7_pre_lowincome)
model7_pre_lowincome$coefficients

Pred11_highincomeV2 <- predict(model7_pre_highincome, newdata = V2)
Pred11_lowincomeV2 <- predict(model7_pre_lowincome, newdata = V2)


Pred11_allincome <- Pred11_highincomeV2

for(i in 1:nrow(Pred11_highincomeV2)){
  for (j in 1:4){
    Pred11_allincome[i,j] <- (Pred11_highincomeV2[i,j]+Pred11_lowincomeV2[i,j])/2
  }
}


# Split data set while keeping id (Number)
v2lowincome_raw = subset(train2,Task > 12 & income<200001)
v2highincome_raw = subset(train2,Task > 12 & income>200000)
Pred11_highincome <- data.frame(predict(model7_pre_highincome, newdata = V2highincome))
Pred11_lowincome <- data.frame(predict(model7_pre_lowincome, newdata = V2lowincome))
Pred11_income_split <- data.frame(No = subset(train2,Task>12)[,"No"])

for(i in 1:nrow(v2lowincome_raw)){
  Pred11_lowincome$No[i] <- v2lowincome_raw[i,"No"]
}
for(i in 1:nrow(v2highincome_raw)){
  Pred11_highincome$No[i] <- v2highincome_raw[i,"No"]
}
s <- rbind(Pred11_highincome,Pred11_lowincome)
Pred11_income_split = merge(x = Pred11_income_split, y = s, by = "No")
Pred11_income_split <- Pred11_income_split[,-(1)]


PredictChoice11avg <- apply(Pred11_allincome, 1, which.max)

PredictChoice11highincome <- apply(Pred11_highincome, 1, which.max)
PredictChoice11lowincome <- apply(Pred11_lowincome, 1, which.max)

prediction_score(ActualChoice, Pred7_pre)
prediction_score(ActualChoice, Pred11_allincome)
prediction_score(ActualChoice, Pred11_highincomeV2)
prediction_score(ActualChoice, Pred11_lowincomeV2)
prediction_score(ActualChoice, Pred11_income_split)



```

```{r model15 with segment split}

model7_pre_fullsize <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb, data = D2fullsize_pickup)
model7_pre_midsize_car <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb, data = D2midsize_car)
model7_pre_midsize_utility <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb, data = D2midsize_utility)
model7_pre_luxury_utility <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb, data = D2luxury_utility)
model7_pre_luxury_sedan <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb, data = D2luxury_sedan)
model7_pre_small_car <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb, data = D2small_car)



Pred11_fullsizeV2 <- predict(model7_pre_fullsize, newdata = V2)
Pred11_midsize_carV2 <- predict(model7_pre_midsize_car, newdata = V2)
Pred11_midsize_utilityV2 <- predict(model7_pre_midsize_utility, newdata = V2)
Pred11_luxury_utiltyV2 <- predict(model7_pre_luxury_utility, newdata = V2)
Pred11_luxury_sedanV2 <- predict(model7_pre_luxury_sedan, newdata = V2)
Pred11_small_carV2 <- predict(model7_pre_small_car, newdata = V2)



Pred11_allsegments <- Pred11_fullsizeV2

for(i in 1:nrow(Pred11_fullsizeV2)){
  for (j in 1:4){
    Pred11_allsegments[i,j] <- (Pred11_fullsizeV2[i,j]+Pred11_midsize_carV2[i,j]+Pred11_midsize_utilityV2[i,j]+Pred11_luxury_utiltyV2[i,j]+Pred11_luxury_sedanV2[i,j]+Pred11_small_carV2[i,j])/6
  }
}

# Split data set while keeping id (Number)
v2fullsize_raw = subset(train2,Task > 12 & train2$segment=="Full-size Pickup")
v2midsize_car_raw = subset(train2,Task > 12 & train2$segment=="Midsize Car")
v2midsize_utility_raw = subset(train2,Task > 12 & train2$segment=="Midsize Luxury Utility segements")
v2luxury_utility_raw = subset(train2,Task > 12 & train2$segment=="Midsize Utility")
v2luxury_sedan_raw = subset(train2,Task > 12 & train2$segment=="Prestige Luxury Sedan")
v2small_car_raw = subset(train2,Task > 12 & train2$segment=="Small Car")



Pred11_fullsize <- data.frame(predict(model7_pre_fullsize, newdata = v2fullsize_raw))
Pred11_midsize_car <- data.frame(predict(model7_pre_midsize_car, newdata = v2midsize_car_raw))
Pred11_midsize_utility <- data.frame(predict(model7_pre_midsize_utility, newdata = v2midsize_utility_raw))
Pred11_luxury_utilty <- data.frame(predict(model7_pre_luxury_utility, newdata = v2luxury_utility_raw))
Pred11_luxury_sedan <- data.frame(predict(model7_pre_luxury_sedan, newdata = v2luxury_sedan_raw))
Pred11_small_car <- data.frame(predict(model7_pre_small_car, newdata = v2small_car_raw))


Pred11_segment_split <- data.frame(No = subset(train2,Task>12)[,"No"])


for(i in 1:nrow(v2fullsize_raw)){
  Pred11_fullsize$No[i] <- v2fullsize_raw[i,"No"]
}
for(i in 1:nrow(v2midsize_car_raw)){
  Pred11_midsize_car$No[i] <- v2midsize_car_raw[i,"No"]
}
for(i in 1:nrow(v2midsize_utility_raw)){
  Pred11_midsize_utility$No[i] <- v2midsize_utility_raw[i,"No"]
}
for(i in 1:nrow(v2luxury_utility_raw)){
  Pred11_luxury_utilty$No[i] <- v2luxury_utility_raw[i,"No"]
}
for(i in 1:nrow(v2luxury_sedan_raw)){
  Pred11_luxury_sedan$No[i] <- v2luxury_sedan_raw[i,"No"]
}
for(i in 1:nrow(v2small_car_raw)){
  Pred11_small_car$No[i] <- v2small_car_raw[i,"No"]
}
s <- rbind(Pred11_fullsize,Pred11_midsize_car,Pred11_midsize_utility,Pred11_luxury_utilty,Pred11_luxury_sedan,Pred11_small_car)
Pred11_segment_split = merge(x = Pred11_segment_split, y = s, by = "No")
Pred11_segment_split <- Pred11_segment_split[,-(1)]



prediction_score(ActualChoice, Pred7_pre)
prediction_score(ActualChoice, Pred11_allsegments)
prediction_score(ActualChoice, Pred11_segment_split)
prediction_score(ActualChoice, Pred11_fullsizeV2)
prediction_score(ActualChoice, Pred11_midsize_carV2)
prediction_score(ActualChoice, Pred11_midsize_utilityV2)
prediction_score(ActualChoice, Pred11_luxury_utiltyV2)
prediction_score(ActualChoice, Pred11_luxury_sedanV2)
prediction_score(ActualChoice, Pred11_small_carV2)

```


#use low income and all ages!

```{r combine income and age}


Pred11_allageincome <- Pred11_allages

for(i in 1:nrow(Pred11_allageincome)){
  for (j in 1:4){
    Pred11_allageincome[i,j] <- (Pred11_allages[i,j]+Pred11_lowincome[i,j])/2
  }
}

prediction_score(ActualChoice, Pred7_pre)
prediction_score(ActualChoice, Pred11_allages)
prediction_score(ActualChoice, Pred11_lowincome)
prediction_score(ActualChoice, Pred11_allageincome)

```

```{r income age and midsize car}

Pred11_allageincome_midsizecar <- Pred11_allages

for(i in 1:nrow(Pred11_allageincome_midsizecar)){
  for (j in 1:4){
    Pred11_allageincome_midsizecar[i,j] <- (Pred11_allages[i,j]+Pred11_lowincome[i,j]+Pred11_midsize_car[i,j])/2
  }
}

prediction_score(ActualChoice, Pred7_pre)
prediction_score(ActualChoice, Pred11_allages)
prediction_score(ActualChoice, Pred11_lowincome)
prediction_score(ActualChoice, Pred11_allageincome_midsizecar)


```


```{r validate model 8}
set.seed(1)

model8 <- mlogit(Choice~GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price - 1|year+region+segment, data = D2)

#model8 <- mlogit(Choice~GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+HU+Price - 1|miles+region+segment+income, data = D2)

#model8 <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1 |educ+night+ppark+region+segment, data = D2)
#took out educ, income
summary(model8)

Pred8 <- predict(model8, newdata = V2)

PredictChoice8 <- apply(Pred8, 1, which.max)

prediction_score(ActualChoice2, Pred8)

t8 <- table(ActualChoice2, PredictChoice8)


accurate_cnt <- c()
for(i in 1:1){
  accurate_cnt <- c(accurate_cnt, 0)
  for(j in 1:4){
    accurate_cnt[i] <- accurate_cnt[i] + t8[j,j]
  }
}
accurate_cnt/4550
#without income
#using educincome, wo year 0.5116484
#without educ, year 0.5125275
#without income, year 0.5136264
#without educ, income 0.5162637
#without above and region, 0.5074725
#without all factors, 0.4859341
#with educ+night+ppark+region+segment 0.5134066

```

```{r Pred 8 submission}

model8A <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1 |year+miles+region+segment, data = A2)

summary(model8A)

Pred8A <- predict(model8A, newdata = test2)


#write file
Submission8A <- submission
for (i in 1:nrow(Pred8A)){
  for (j in colnames(Pred8A)){
    Submission8A[i,j] = Pred8A[i,j]
  }
}
write.csv(Submission8A, file = 'Submission7.csv')

```

```{r Pred 9}
model9 <- mlogit(Choice~GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+HU+Price|miles+region+segment+income, data = A2)

summary(model9)

predict9 <- predict(model9, newdata = test2)


#write file
Submission9 <- submission
for (i in 1:nrow(predict9)){
  for (j in colnames(predict9)){
    Submission9[i,j] = predict9[i,j]
  }
}
write.csv(Submission9, file = 'Submission9.csv')

```

```{r Pred 10}
model10 <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb, data = D2, probit=TRUE)

summary(model10)

predict10 <- predict(model10, newdata = test2)

PredictChoice10 <- apply(predict10, 1, which.max)
t10 <- table(ActualChoice2, PredictChoice10)


accurate_cnt <- c()
for(i in 1:1){
  accurate_cnt <- c(accurate_cnt, 0)
  for(j in 1:4){
    accurate_cnt[i] <- accurate_cnt[i] + t10[j,j]
  }
}
accurate_cnt/4550
```


```{r compare accuracy}
accurate_cnt <- c()
for(i in 1:5){
  accurate_cnt <- c(accurate_cnt, 0)
  for(j in 1:4){
    accurate_cnt[i] <- accurate_cnt[i] + choiceVector[[i]][j,j]
  }
}
accurate_cnt/4550
```
best prediction
all variables without educ, income, ppark: 51.4%
all variables: 50.989%
3 star variables: 50.791%
2 star variables: 50.989%
1 star variables: 50.83%

```{r pred 7 submission}
#write file
Submission6 <- submission
for (i in 1:nrow(Pred1A)){
  for (j in colnames(Pred1A)){
    Submission6[i,j] = Pred1A[i,j]
  }
}
write.csv(Submission6, file = 'Submission6.csv')

```

```{r model 9}
model9 <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price | gender+miles+night+age+Urb , data = D2, rpar = c(CC = 'n',  GN = 'n',  NS = 'n',  BU = 'n',  FA = 'n',  LD = 'n',  BZ = 'n',  FC = 'n',  FP = 'n',  RP = 'n',  PP = 'n',  KA = 'n',  SC = 'n',  TS = 'n',  NV = 'n',  MA = 'n',  LB = 'n',  AF = 'n',  HU = 'n', Price = 'n'), panel = TRUE, print.level = TRUE)
summary(model9)

```

```{r validate 9}
pred9 <- predict(model9, newdata = V2)
choice9 <- apply(pred9, 1, which.max)
t9 <- table(ActualChoice2, choice9)


accurate_cnt <- c()
for(i in 1:1){
  accurate_cnt <- c(accurate_cnt, 0)
  for(j in 1:4){
    accurate_cnt[i] <- accurate_cnt[i] + t9[j,j]
  }
}
accurate_cnt/4550
#50.7% accuracy
```

```{r multinomial probit}
library('MNP')
res <- mnp()

predict_nn <- predict(mod, test_nn,"probs")
choice_nn <- apply(predict_nn, 1, which.max)
t_chi <- table(ActualChoice2, choice_nn)


accurate_cnt <- c()
for(i in 1:1){
  accurate_cnt <- c(accurate_cnt, 0)
  for(j in 1:4){
    accurate_cnt[i] <- accurate_cnt[i] + t9[j,j]
  }
}
accurate_cnt/4550
```

```{r neural network}

train_nn <- subset(train, Task <= 12)
test_nn <- subset(train, Task > 12)

mod <- multinom(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+miles+night+age+Urb, data=D2)

predict_nn <- predict(mod, V2,"probs")
choice_nn <- apply(predict_nn, 1, which.max)
t_nn <- table(ActualChoice2, choice_nn)


accurate_cnt <- c()
for(i in 1:1){
  accurate_cnt <- c(accurate_cnt, 0)
  for(j in 1:4){
    accurate_cnt[i] <- accurate_cnt[i] + t_nn[j,j]
  }
}
accurate_cnt/4550
```

```{r}
model11 <- mlogit(Choice~GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price -1| gender+age+Urb, data = A2)

predict11 <- predict(model11, newdata = test2)


#write file
Submission11 <- submission
for (i in 1:nrow(predict11)){
  for (j in colnames(predict11)){
    Submission11[i,j] = predict11[i,j]
  }
}
write.csv(Submission11, file = 'Submission11.csv')
```


##CART

```{r cart}
library(rpart)
library(rpart.plot)

train_split =read.csv("output.csv")

cart1 = rpart(Choice~CC1+GN1+NS1+BU1+FA1+LD1+BZ1+FC1+FP1+RP1+PP1+KA1+SC1+TS1+NV1+MA1+LB1+AF1+HU1+Price1+CC2+GN2+NS2+BU2+FA2+LD2+BZ2+FC2+FP2+RP2+PP2+KA2+SC2+TS2+NV2+MA2+LB2+AF2+HU2+Price2+CC3+GN3+NS3+BU3+FA3+LD3+BZ3+FC3+FP3+RP3+PP3+KA3+SC3+TS3+NV3+MA3+LB3+AF3+HU3+Price3+CC4+GN4+NS4+BU4+FA4+LD4+BZ4+FC4+FP4+RP4+PP4+KA4+SC4+TS4+NV4+MA4+LB4+AF4+HU4+Price4,data=train,method = "class") 
cart2 = rpart(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price,data=train_split,method="class") 

prp(cart1)
prp(cart2)
```

```{r cross-validation with six models}

```

##Clustering Models

###Using factors

```{r pre-processing data}

#ClusterTrainData <- train[train$Task == 1,c(84,86:94)]
ClusterTrainData <- train[train$Task == 1,c(88:89,92)]
fac <- factor(c())
levels <- c()
for(i in c('gender', 'age', 'Urb')){
  #print(levels(ClusterTrainData[,i]))
  fac <- union(fac, levels(ClusterTrainData[,i]))
}
start = 1
for(i in colnames(ClusterTrainData)){
  end = start + length(levels(ClusterTrainData[,i])) - 1
  for(j in fac[start:end]){
    #print(c(i,j))
    ClusterTrainData[j] <- ClusterTrainData[,i] == j
  }
  start = end + 1
  ClusterTrainData[,i] <- NULL
}

#ClusterTestData <- test[test$Task == 1,c(84,86:94)]
ClusterTestData <- test[test$Task == 1,c(84,86:89,91:92)]
fac <- factor(c())
levels <- c()
for(i in colnames(ClusterTestData)){
  #print(levels(ClusterTrainData[,i]))
  fac <- union(fac, levels(ClusterTestData[,i]))
}
start = 1
for(i in colnames(ClusterTestData)){
  end = start + length(levels(ClusterTestData[,i])) - 1
  for(j in fac[start:end]){
    #print(c(i,j))
    ClusterTestData[j] <- ClusterTestData[,i] == j
  }
  start = end + 1
  ClusterTestData[,i] <- NULL
}

```

```{r clustering and modelling using kmeans & numerical variables}
actualVector <- vector(mode = "list", length = 6)
trainVector <- vector(mode = "list", length = 6)
validateVector <- vector(mode = "list", length = 6)

scores <- vector(mode="list", length = 10)

for(i in 2:10){
  cluster <- kmeans(ClusterTrainData, centers = i)
  clusterTrain <- train
  clusterTest <- test
  clusterTrain$cluster <- cluster$cluster[clusterTrain$Case]
  clusterTest$cluster <- cluster$cluster[clusterTest$Case]
  models <- vector(mode = "list", length = i)


  
  start <- c(1, 4, 7, 10, 13, 16)
  stop <- c(4, 7, 10, 13, 16, 19)
  score_for_cluster_size = c()  
  score <- c()
  for (j in 1:6){
    trainVector[[j]] <-subset(clusterTrain, Task >= start[j]&Task < stop[j]) 
    validateVector[[j]] <-subset(clusterTrain, !(Task >= start[j]&Task < stop[j]))
    actualVector[[j]] <-subset(clusterTrain, !(Task >= start[j]&Task < stop[j]))[,'Choice']
    
    temp <- validateVector[[j]]
    temp$p1 <- 0
    temp$p2 <- 0
    temp$p3 <- 0
    temp$p4 <- 0
    for(k in 1:i){
      filteredTrain <- trainVector[[j]]
      filteredTrain <- filteredTrain[filteredTrain$cluster == k,]  
      filteredV <- validateVector[[j]]
      filteredV <- filteredV[filteredV$cluster == k,]  
      
      DC <- mlogit.data(filteredTrain, shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
        
      VC <- mlogit.data(filteredV, shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
      
      model1 <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = DC)
      
      predictmodel1 <- predict(model1, newdata = VC)
      l <- 1
      for (row in temp[temp$cluster == k,]$No){
          temp[temp$No == row,101] <- predictmodel1[l,1]
          temp[temp$No == row,102] <- predictmodel1[l,2]
          temp[temp$No == row,103] <- predictmodel1[l,3]
          temp[temp$No == row,104] <- predictmodel1[l,4]
          l <- l+1
      }
    }
    score <- c(score, prediction_score(actualVector[[j]], temp[,101:104]))
    #print(c('cluster',j,'length',nrow(filteredTrain)))
    #print(score)
  }
  print(score)
}

```

It is established that using five clusters yield the best results during validation.

```{r predicting test case}
closest.cluster <- function(x) {
  cluster.dist <- apply(km$centers, 1, function(y) sqrt(sum((x-y)^2)))
  return(which.min(cluster.dist)[1])
}

km <- kmeans(ClusterTrainData, centers = 4)
clusterTrain$cluster <- km$cluster[clusterTrain$Case]
clusterTest$cluster <- apply(ClusterTestData, 1, closest.cluster)

all_predictions <- data.frame()

for(j in 1:5){
#    print(c('cluster',j))
  filteredTrain <- clusterTrain[clusterTrain$cluster == j,]
  filteredTest <- clusterTest[clusterTest$cluster == j & !is.na(clusterTest$cluster == j),]
  #print(c('cluster',j,'length',nrow(filteredTrain)))
  
  AC <- mlogit.data(filteredTrain, shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
  
  TestC <- mlogit.data(filteredTest, shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
  TestC$Ch1 = 0
  TestC$Ch2 = 0
  TestC$Ch3 = 0
  TestC$Ch4 = 0
  TestC$Choice = FALSE

  modelC <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = AC)
  index <- filteredTest$No
  predictC <- data.frame(predict(modelC, newdata = TestC))
  predictC$index <- index
  all_predictions <- rbind(all_predictions, predictC)
}

#Using base model for nulls

filteredTest <- clusterTest[is.na(clusterTest$cluster == j),]
TestC <- mlogit.data(filteredTest, shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
TestC$Ch1 = 0
TestC$Ch2 = 0
TestC$Ch3 = 0
TestC$Ch4 = 0
TestC$Choice = FALSE
index <- filteredTest$No
predictC <- data.frame(predict(model1A, newdata = TestC))
predictC$index <- index
all_predictions <- rbind(all_predictions, predictC)

Submission8 <- submission
for (i in 1:nrow(Submission8)){
  index <- Submission8[i,]$No
  for (j in colnames(TestPredict)){
    Submission8[i,j] = all_predictions[all_predictions$index == index,][,j]
  }
}
write.csv(Submission8, file = 'Submission8.csv')

```

###Using numbers

```{r pre-processing data}
ClusterTrainData <- train2[train2$Task == 1,c(88:89,92)]
fac <- factor(c())
for(i in c('gender', 'age', 'Urb')){
  #print(levels(ClusterTrainData[,i]))
  fac <- union(levels(ClusterTrainData[,i]), fac)
}
for(i in fac[1:5]){
  ClusterTrainData[i] <- ClusterTrainData$region == i
}
for(i in fac[5:11]){
  ClusterTrainData[i] <- ClusterTrainData$segment == i
}
ClusterTrainData$region <- NULL
ClusterTrainData$segment <- NULL
#fac <- factor(c())
#for(i in colnames(ClusterTrainData)){
#  #print(levels(ClusterTrainData[,i]))
#  fac <- union(levels(ClusterTrainData[,i]), fac)
#}
clusterVector <- vector(mode = "list", length = 9)
```

```{r clustering and modelling using kmeans & numerical variables}
for(i in 1:10){
  cluster <- kmeans(ClusterTrainData, centers = i)
  clusterTrain <- train2
  clusterTest <- test2
  clusterTrain$cluster <- cluster$cluster[clusterTrain$Case]
  clusterTest$cluster <- cluster$cluster[clusterTest$Case]
  models <- vector(mode = "list", length = i)
  total_correct = 0
  print(i)
  for(j in 1:i){
#    print(c('cluster',j))
    filteredTrain <- clusterTrain[clusterTrain$cluster == j,]
    #print(c('cluster',j,'length',nrow(filteredTrain)))
    
    AC <- mlogit.data(filteredTrain, shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
    
    DC <- mlogit.data(subset(filteredTrain, Task <= 12), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
    
    VC <- mlogit.data(subset(filteredTrain, Task > 12), shape = 'wide', choice = "Choice", varying = c(4:83), sep = '', alt.levels = c("Ch1", "Ch2", "Ch3", "Ch4"), id.var = "Case")
    
    ActualChoiceC <- subset(filteredTrain, Task > 12)[,"Choice"]
    
    modelC <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = DC)
    
    predictC <- predict(modelC, newdata = VC)
    PredictChoiceC <- apply(predictC, 1, which.max)
    t <- table(PredictChoiceC, ActualChoiceC)
    #print(t)
    correct <- 0
    for (choice in 1:4){
      correct = correct + t[choice,choice]
    }
    total_correct = total_correct + correct
    #print(total_correct)
  }
  print(total_correct)
}

```

We establish that k = 2 is best but loses to baseline model
###Using pnn
```{r pnn code}
#D2copy <- D2
#V2copy <- V2
D2 <- D2copy
V2 <- V2copy
str(D2$Ch1)

D2$Choice <- ifelse(D2$Ch1 == 1, D2$Choice <- "Ch1", ifelse(D2$Ch2 == 1, D2$Choice <- "Ch2", ifelse(D2$Ch3 ==1, D2$Choice <- "Ch3", ifelse(D2$Ch4==1, D2$Choice <- "Ch4", "NA"))))

str(D2)

t.df_pre <- subset(D2, select=c(19,5:10,12:14,20:40))
t.df <- data.frame(t.df_pre)

#install.packages("pnn")
library(pnn)

train <- learn(t.df)
fit <- smooth(train)
#install.packages("rgenoud")
str(t.df$Choice)
summary(train)
?smooth
?pnn


V2$Choice <- ifelse(V2$Ch1 == 1, V2$Choice <- "Ch1", ifelse(V2$Ch2 == 1, V2$Choice <- "Ch2", ifelse(V2$Ch3 ==1, V2$Choice <- "Ch3", ifelse(V2$Ch4==1, V2$Choice <- "Ch4", "NA"))))

q.df_pre <- subset(V2, select=c(19,5:10,12:14,20:40))
names(q.df_pre)
q.df <- data.frame(q.df_pre)
train$categories

n <- nrow(q.df)
Q <- rep(0, n)
for (i in 1:n) {
print(i)
  
Q[i] <- guess(fit, as.matrix(q.df[i,1:2]))$probabilities
    }
    R <- data.frame(q.df, Q, stringsAsFactors = FALSE)
    P <- subset(R, Q == 1)
    N <- subset(R, Q == 0)
Q
```
